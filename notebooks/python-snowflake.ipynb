{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ee9a8f",
   "metadata": {},
   "source": [
    "See python-snowflake handout for details.\n",
    "\n",
    "What you will need to do:\n",
    "\n",
    "In Snowflake:\n",
    "- Collect the account information, warehouse name, database name, etc (See Snowflake connection info below)\n",
    "- Temporarily disable MFA if it is enabled\n",
    "- Make sure you know the number of rows and the total for a numeric column for testing.\n",
    "\n",
    "In VSC:\n",
    "- Create a new file to hold the environment variables (the snowflake data above)\n",
    "\n",
    "In python notebook:\n",
    "- Install the snowflake-connector\n",
    "- Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45affb96-5b49-4e7a-91ef-41e0f72af6eb",
   "metadata": {},
   "source": [
    "# Snowflake Connection\n",
    "\n",
    "- SNOWFLAKE_ACCOUNT=your_account_identifier\n",
    "- SNOWFLAKE_USER=your_username\n",
    "- SNOWFLAKE_PASSWORD=your_password\n",
    "- SNOWFLAKE_WAREHOUSE=your_warehouse_name\n",
    "- SNOWFLAKE_DATABASE=your_database_name\n",
    "- SNOWFLAKE_SCHEMA=your_schema_name\n",
    "- SNOWFLAKE_ROLE=your_role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acd3af7c-e663-45ef-95cd-46d8cf5dc4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install snowflake-connector-python pyarrow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7b5e47-d7db-4726-8cd3-02b28927fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d95624-8c24-439d-8e9c-52aa677aae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500000,)\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve values\n",
    "user = os.getenv(\"SNOWFLAKE_USER\")\n",
    "password = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
    "account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
    "warehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "database = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
    "schema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    "role = os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "\n",
    "# user = SNOWFLAKE_USER\n",
    "# password = SNOWFLAKE_PASSWORD\n",
    "# account = SNOWFLAKE_ACCOUNT\n",
    "# warehouse = SNOWFLAKE_WAREHOUSE\n",
    "# database = SNOWFLAKE_DATABASE\n",
    "# schema = SNOWFLAKE_SCHEMA\n",
    "# role = SNOWFLAKE_ROLE\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a query\n",
    "cur.execute(\"SELECT count(*) from orders\")\n",
    "\n",
    "# Fetch result\n",
    "print(cur.fetchone())\n",
    "\n",
    "# Clean up\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67068509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200001</td>\n",
       "      <td>121361</td>\n",
       "      <td>F</td>\n",
       "      <td>60106.33</td>\n",
       "      <td>1994-01-24</td>\n",
       "      <td>1-URGENT</td>\n",
       "      <td>Clerk#000000340</td>\n",
       "      <td>0</td>\n",
       "      <td>ourts are carefully above the slyly final theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200002</td>\n",
       "      <td>1775</td>\n",
       "      <td>O</td>\n",
       "      <td>194561.08</td>\n",
       "      <td>1996-12-06</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000709</td>\n",
       "      <td>0</td>\n",
       "      <td>ts. ironic sheaves along the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200003</td>\n",
       "      <td>122593</td>\n",
       "      <td>F</td>\n",
       "      <td>10061.57</td>\n",
       "      <td>1994-01-23</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000141</td>\n",
       "      <td>0</td>\n",
       "      <td>bravely final accounts serve. carefully regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200004</td>\n",
       "      <td>6394</td>\n",
       "      <td>O</td>\n",
       "      <td>206408.82</td>\n",
       "      <td>1996-06-10</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000545</td>\n",
       "      <td>0</td>\n",
       "      <td>posits wake carefully. pinto beans sleep. b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200005</td>\n",
       "      <td>57130</td>\n",
       "      <td>F</td>\n",
       "      <td>234800.62</td>\n",
       "      <td>1995-01-04</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000473</td>\n",
       "      <td>0</td>\n",
       "      <td>tes. fluffily even packages into the regular g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499995</th>\n",
       "      <td>4199972</td>\n",
       "      <td>135494</td>\n",
       "      <td>F</td>\n",
       "      <td>234876.94</td>\n",
       "      <td>1992-11-20</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000642</td>\n",
       "      <td>0</td>\n",
       "      <td>anent packages around the e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499996</th>\n",
       "      <td>4199973</td>\n",
       "      <td>97459</td>\n",
       "      <td>F</td>\n",
       "      <td>55190.12</td>\n",
       "      <td>1992-12-25</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000063</td>\n",
       "      <td>0</td>\n",
       "      <td>ully even pinto beans cajole furiously along</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499997</th>\n",
       "      <td>4199974</td>\n",
       "      <td>118453</td>\n",
       "      <td>O</td>\n",
       "      <td>221822.59</td>\n",
       "      <td>1997-06-18</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000313</td>\n",
       "      <td>0</td>\n",
       "      <td>s haggle around the even excuses. quic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499998</th>\n",
       "      <td>4199975</td>\n",
       "      <td>35011</td>\n",
       "      <td>O</td>\n",
       "      <td>134591.43</td>\n",
       "      <td>1996-07-09</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000248</td>\n",
       "      <td>0</td>\n",
       "      <td>nal theodolites use furiously unusual asymptot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499999</th>\n",
       "      <td>4200000</td>\n",
       "      <td>97987</td>\n",
       "      <td>F</td>\n",
       "      <td>8941.89</td>\n",
       "      <td>1992-02-25</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000496</td>\n",
       "      <td>0</td>\n",
       "      <td>regular pains. blithel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0           1200001     121361             F      60106.33  1994-01-24   \n",
       "1           1200002       1775             O     194561.08  1996-12-06   \n",
       "2           1200003     122593             F      10061.57  1994-01-23   \n",
       "3           1200004       6394             O     206408.82  1996-06-10   \n",
       "4           1200005      57130             F     234800.62  1995-01-04   \n",
       "...             ...        ...           ...           ...         ...   \n",
       "1499995     4199972     135494             F     234876.94  1992-11-20   \n",
       "1499996     4199973      97459             F      55190.12  1992-12-25   \n",
       "1499997     4199974     118453             O     221822.59  1997-06-18   \n",
       "1499998     4199975      35011             O     134591.43  1996-07-09   \n",
       "1499999     4200000      97987             F       8941.89  1992-02-25   \n",
       "\n",
       "        O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0              1-URGENT  Clerk#000000340               0   \n",
       "1                2-HIGH  Clerk#000000709               0   \n",
       "2                2-HIGH  Clerk#000000141               0   \n",
       "3              3-MEDIUM  Clerk#000000545               0   \n",
       "4                2-HIGH  Clerk#000000473               0   \n",
       "...                 ...              ...             ...   \n",
       "1499995          2-HIGH  Clerk#000000642               0   \n",
       "1499996          2-HIGH  Clerk#000000063               0   \n",
       "1499997           5-LOW  Clerk#000000313               0   \n",
       "1499998        3-MEDIUM  Clerk#000000248               0   \n",
       "1499999        3-MEDIUM  Clerk#000000496               0   \n",
       "\n",
       "                                                 O_COMMENT  \n",
       "0        ourts are carefully above the slyly final theo...  \n",
       "1                             ts. ironic sheaves along the  \n",
       "2        bravely final accounts serve. carefully regula...  \n",
       "3              posits wake carefully. pinto beans sleep. b  \n",
       "4        tes. fluffily even packages into the regular g...  \n",
       "...                                                    ...  \n",
       "1499995                        anent packages around the e  \n",
       "1499996      ully even pinto beans cajole furiously along   \n",
       "1499997             s haggle around the even excuses. quic  \n",
       "1499998  nal theodolites use furiously unusual asymptot...  \n",
       "1499999                             regular pains. blithel  \n",
       "\n",
       "[1500000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "conn = snowflake.connector.connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    role=role,\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a query and load into DataFrame\n",
    "cur.execute(\"SELECT * FROM orders\")\n",
    "result_df = cur.fetch_pandas_all()\n",
    "\n",
    "# Clean up\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37d9e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_COUNT\n",
      "0      19217\n",
      "Batch 1: 1096 rows\n",
      "Batch 2: 4533 rows\n",
      "Batch 3: 6790 rows\n",
      "Batch 4: 15912 rows\n",
      "Batch 1: 1096 rows\n",
      "Batch 2: 4533 rows\n",
      "Batch 3: 6790 rows\n",
      "Batch 4: 15912 rows\n",
      "Batch 5: 27051 rows\n",
      "Batch 5: 27051 rows\n",
      "Batch 6: 57637 rows\n",
      "Batch 7: 36981 rows\n",
      "Batch 8: 1094 rows\n",
      "Batch 9: 4541 rows\n",
      "Batch 10: 6833 rows\n",
      "Batch 6: 57637 rows\n",
      "Batch 7: 36981 rows\n",
      "Batch 8: 1094 rows\n",
      "Batch 9: 4541 rows\n",
      "Batch 10: 6833 rows\n",
      "Batch 11: 15921 rows\n",
      "Batch 11: 15921 rows\n",
      "Batch 12: 27068 rows\n",
      "Batch 13: 57759 rows\n",
      "Batch 14: 36784 rows\n",
      "Batch 15: 1099 rows\n",
      "Batch 16: 4554 rows\n",
      "Batch 12: 27068 rows\n",
      "Batch 13: 57759 rows\n",
      "Batch 14: 36784 rows\n",
      "Batch 15: 1099 rows\n",
      "Batch 16: 4554 rows\n",
      "Batch 17: 6808 rows\n",
      "Batch 18: 15929 rows\n",
      "Batch 19: 26995 rows\n",
      "Batch 17: 6808 rows\n",
      "Batch 18: 15929 rows\n",
      "Batch 19: 26995 rows\n",
      "Batch 20: 57720 rows\n",
      "Batch 21: 36895 rows\n",
      "Batch 22: 1105 rows\n",
      "Batch 23: 4532 rows\n",
      "Batch 24: 6841 rows\n",
      "Batch 20: 57720 rows\n",
      "Batch 21: 36895 rows\n",
      "Batch 22: 1105 rows\n",
      "Batch 23: 4532 rows\n",
      "Batch 24: 6841 rows\n",
      "Batch 25: 15879 rows\n",
      "Batch 26: 27089 rows\n",
      "Batch 25: 15879 rows\n",
      "Batch 26: 27089 rows\n",
      "Batch 27: 57797 rows\n",
      "Batch 27: 57797 rows\n",
      "Batch 28: 103895 rows\n",
      "Batch 29: 82862 rows\n",
      "Batch 30: 1112 rows\n",
      "Batch 31: 4560 rows\n",
      "Batch 32: 6786 rows\n",
      "Batch 28: 103895 rows\n",
      "Batch 29: 82862 rows\n",
      "Batch 30: 1112 rows\n",
      "Batch 31: 4560 rows\n",
      "Batch 32: 6786 rows\n",
      "Batch 33: 15906 rows\n",
      "Batch 34: 27055 rows\n",
      "Batch 33: 15906 rows\n",
      "Batch 34: 27055 rows\n",
      "Batch 35: 57681 rows\n",
      "Batch 36: 36900 rows\n",
      "Batch 37: 1110 rows\n",
      "Batch 38: 4539 rows\n",
      "Batch 39: 6794 rows\n",
      "Batch 35: 57681 rows\n",
      "Batch 36: 36900 rows\n",
      "Batch 37: 1110 rows\n",
      "Batch 38: 4539 rows\n",
      "Batch 39: 6794 rows\n",
      "Batch 40: 15898 rows\n",
      "Batch 41: 27107 rows\n",
      "Batch 40: 15898 rows\n",
      "Batch 41: 27107 rows\n",
      "Batch 42: 57771 rows\n",
      "Batch 42: 57771 rows\n",
      "Batch 43: 103789 rows\n",
      "Batch 44: 82992 rows\n",
      "Batch 45: 1107 rows\n",
      "Batch 46: 4553 rows\n",
      "Batch 47: 6795 rows\n",
      "Batch 43: 103789 rows\n",
      "Batch 44: 82992 rows\n",
      "Batch 45: 1107 rows\n",
      "Batch 46: 4553 rows\n",
      "Batch 47: 6795 rows\n",
      "Batch 48: 15912 rows\n",
      "Batch 49: 27055 rows\n",
      "Batch 48: 15912 rows\n",
      "Batch 49: 27055 rows\n",
      "Batch 50: 57672 rows\n",
      "Batch 51: 36906 rows\n",
      "Batch 52: 1111 rows\n",
      "Batch 53: 4548 rows\n",
      "Batch 54: 6799 rows\n",
      "Batch 50: 57672 rows\n",
      "Batch 51: 36906 rows\n",
      "Batch 52: 1111 rows\n",
      "Batch 53: 4548 rows\n",
      "Batch 54: 6799 rows\n",
      "Batch 55: 15898 rows\n",
      "Batch 55: 15898 rows\n",
      "Batch 56: 27052 rows\n",
      "Batch 56: 27052 rows\n",
      "Batch 57: 57706 rows\n",
      "Batch 58: 36886 rows\n",
      "Total rows fetched: 1500000\n",
      "Batch 57: 57706 rows\n",
      "Batch 58: 36886 rows\n",
      "Total rows fetched: 1500000\n"
     ]
    }
   ],
   "source": [
    "# Parameterized queries and efficient fetching helpers\n",
    "from typing import Dict, Iterable, Optional\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "\n",
    "\n",
    "def _get_conn():\n",
    "    \"\"\"Open a fresh Snowflake connection using env vars already loaded above.\"\"\"\n",
    "    return snowflake.connector.connect(\n",
    "        user=user,\n",
    "        password=password,\n",
    "        account=account,\n",
    "        warehouse=warehouse,\n",
    "        database=database,\n",
    "        schema=schema,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "\n",
    "def fetch_df(sql: str, params: Optional[Dict] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a parameterized query and return a single pandas DataFrame.\n",
    "    Use for smaller result sets.\n",
    "    Example:\n",
    "        df = fetch_df(\n",
    "            \"SELECT COUNT(*) AS row_count FROM orders WHERE O_ORDERDATE >= %(start)s AND O_ORDERDATE < %(end)s\",\n",
    "            {\"start\": \"1996-01-01\", \"end\": \"1996-02-01\"},\n",
    "        )\n",
    "    \"\"\"\n",
    "    with _get_conn() as _conn:\n",
    "        with _conn.cursor() as _cur:\n",
    "            _cur.execute(sql, params)\n",
    "            return _cur.fetch_pandas_all()\n",
    "\n",
    "\n",
    "def fetch_df_batches(\n",
    "    sql: str,\n",
    "    params: Optional[Dict] = None,\n",
    "    batch_size: int = 100_000,\n",
    ") -> Iterable[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a parameterized query and yield pandas DataFrames in batches.\n",
    "    Uses fetch_pandas_batches when available; falls back to fetchmany.\n",
    "    Example:\n",
    "        total = 0\n",
    "        for i, part in enumerate(\n",
    "            fetch_df_batches(\"SELECT * FROM orders WHERE O_TOTALPRICE > %(min_total)s\", {\"min_total\": 100}), 1\n",
    "        ):\n",
    "            print(f\"Batch {i}: {len(part)} rows\")\n",
    "            total += len(part)\n",
    "        print(\"Total rows:\", total)\n",
    "    \"\"\"\n",
    "    with _get_conn() as _conn:\n",
    "        with _conn.cursor() as _cur:\n",
    "            _cur.execute(sql, params)\n",
    "            # Preferred: use native pandas batches if available (Snowflake Connector >= 3.0)\n",
    "            if hasattr(_cur, \"fetch_pandas_batches\"):\n",
    "                for batch in _cur.fetch_pandas_batches():\n",
    "                    yield batch\n",
    "            else:\n",
    "                # Fallback: build DataFrames from fetchmany\n",
    "                cols = [d[0] for d in _cur.description]\n",
    "                while True:\n",
    "                    rows = _cur.fetchmany(batch_size)\n",
    "                    if not rows:\n",
    "                        break\n",
    "                    yield pd.DataFrame.from_records(rows, columns=cols)\n",
    "\n",
    "\n",
    "# --- Quick smoke tests (safe to run) ---\n",
    "# Small param query\n",
    "try:\n",
    "    example_small = fetch_df(\n",
    "        \"SELECT COUNT(*) AS row_count FROM orders WHERE O_ORDERDATE >= %(start)s AND O_ORDERDATE < %(end)s\",\n",
    "        {\"start\": \"1996-01-01\", \"end\": \"1996-02-01\"},\n",
    "    )\n",
    "    print(example_small)\n",
    "except Exception as e:\n",
    "    print(\"Example small query skipped:\", e)\n",
    "\n",
    "# Large (batched) example\n",
    "try:\n",
    "    total_rows = 0\n",
    "    for i, df_batch in enumerate(\n",
    "        fetch_df_batches(\n",
    "            \"SELECT * FROM orders WHERE O_TOTALPRICE > %(min_total)s\",\n",
    "            params={\"min_total\": 100},\n",
    "            batch_size=200_000,\n",
    "        ),\n",
    "        start=1,\n",
    "    ):\n",
    "        print(f\"Batch {i}: {len(df_batch)} rows\")\n",
    "        total_rows += len(df_batch)\n",
    "    print(\"Total rows fetched:\", total_rows)\n",
    "except Exception as e:\n",
    "    print(\"Batched example skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bbfc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1112 rows to parquet_orders_jan/orders_jan_part_00001.parquet\n",
      "Wrote 802 rows to parquet_orders_jan/orders_jan_part_00002.parquet\n",
      "Wrote 1088 rows to parquet_orders_jan/orders_jan_part_00003.parquet\n",
      "Wrote 887 rows to parquet_orders_jan/orders_jan_part_00004.parquet\n",
      "Wrote 1104 rows to parquet_orders_jan/orders_jan_part_00005.parquet\n",
      "Wrote 770 rows to parquet_orders_jan/orders_jan_part_00006.parquet\n",
      "Wrote 1101 rows to parquet_orders_jan/orders_jan_part_00007.parquet\n",
      "Wrote 833 rows to parquet_orders_jan/orders_jan_part_00008.parquet\n",
      "Wrote 1088 rows to parquet_orders_jan/orders_jan_part_00003.parquet\n",
      "Wrote 887 rows to parquet_orders_jan/orders_jan_part_00004.parquet\n",
      "Wrote 1104 rows to parquet_orders_jan/orders_jan_part_00005.parquet\n",
      "Wrote 770 rows to parquet_orders_jan/orders_jan_part_00006.parquet\n",
      "Wrote 1101 rows to parquet_orders_jan/orders_jan_part_00007.parquet\n",
      "Wrote 833 rows to parquet_orders_jan/orders_jan_part_00008.parquet\n",
      "Wrote 1107 rows to parquet_orders_jan/orders_jan_part_00009.parquet\n",
      "Wrote 796 rows to parquet_orders_jan/orders_jan_part_00010.parquet\n",
      "Wrote 1116 rows to parquet_orders_jan/orders_jan_part_00011.parquet\n",
      "Wrote 1107 rows to parquet_orders_jan/orders_jan_part_00009.parquet\n",
      "Wrote 796 rows to parquet_orders_jan/orders_jan_part_00010.parquet\n",
      "Wrote 1116 rows to parquet_orders_jan/orders_jan_part_00011.parquet\n",
      "Wrote 2660 rows to parquet_orders_jan/orders_jan_part_00012.parquet\n",
      "Wrote 1101 rows to parquet_orders_jan/orders_jan_part_00013.parquet\n",
      "Wrote 872 rows to parquet_orders_jan/orders_jan_part_00014.parquet\n",
      "Wrote 1106 rows to parquet_orders_jan/orders_jan_part_00015.parquet\n",
      "Wrote 2762 rows to parquet_orders_jan/orders_jan_part_00016.parquet\n",
      "Wrote 2660 rows to parquet_orders_jan/orders_jan_part_00012.parquet\n",
      "Wrote 1101 rows to parquet_orders_jan/orders_jan_part_00013.parquet\n",
      "Wrote 872 rows to parquet_orders_jan/orders_jan_part_00014.parquet\n",
      "Wrote 1106 rows to parquet_orders_jan/orders_jan_part_00015.parquet\n",
      "Wrote 2762 rows to parquet_orders_jan/orders_jan_part_00016.parquet\n",
      "Total rows written to Parquet: 19217\n",
      "Total rows written to Parquet: 19217\n"
     ]
    }
   ],
   "source": [
    "# Stream large query results to disk (Parquet/CSV) without holding all rows in memory\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def stream_to_parquet_dir(\n",
    "    sql: str,\n",
    "    params: dict | None = None,\n",
    "    out_dir: str = \"parquet_out\",\n",
    "    base_name: str = \"result\",\n",
    "    batch_size: int = 200_000,\n",
    "    engine: str = \"pyarrow\",\n",
    "    compression: str | None = \"snappy\",\n",
    ") -> int:\n",
    "    \"\"\"Execute a query and write results to multiple Parquet files in batches.\n",
    "    Returns the total number of rows written.\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    total = 0\n",
    "    for i, df_part in enumerate(fetch_df_batches(sql, params=params, batch_size=batch_size), start=1):\n",
    "        part_path = Path(out_dir) / f\"{base_name}_part_{i:05d}.parquet\"\n",
    "        df_part.to_parquet(part_path, engine=engine, index=False, compression=compression)\n",
    "        total += len(df_part)\n",
    "        print(f\"Wrote {len(df_part)} rows to {part_path}\")\n",
    "    print(f\"Total rows written to Parquet: {total}\")\n",
    "    return total\n",
    "\n",
    "\n",
    "def stream_to_csv_dir(\n",
    "    sql: str,\n",
    "    params: dict | None = None,\n",
    "    out_dir: str = \"csv_out\",\n",
    "    base_name: str = \"result\",\n",
    "    batch_size: int = 200_000,\n",
    "    float_format: str | None = None,\n",
    ") -> int:\n",
    "    \"\"\"Execute a query and write results to multiple CSV files in batches.\n",
    "    Returns the total number of rows written.\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    total = 0\n",
    "    for i, df_part in enumerate(fetch_df_batches(sql, params=params, batch_size=batch_size), start=1):\n",
    "        part_path = Path(out_dir) / f\"{base_name}_part_{i:05d}.csv\"\n",
    "        df_part.to_csv(part_path, index=False, float_format=float_format)\n",
    "        total += len(df_part)\n",
    "        print(f\"Wrote {len(df_part)} rows to {part_path}\")\n",
    "    print(f\"Total rows written to CSV: {total}\")\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- Example usage (uncomment to run) ---\n",
    "# total_csv = stream_to_csv_dir(\n",
    "#     \"SELECT * FROM orders WHERE O_TOTALPRICE > %(min_total)s\",\n",
    "#     params={\"min_total\": 100},\n",
    "#     out_dir=\"csv_orders_over_100\",\n",
    "#     base_name=\"orders_over_100\",\n",
    "#     batch_size=250_000,\n",
    "# )\n",
    "\n",
    "total_parquet = stream_to_parquet_dir(\n",
    "    \"SELECT * FROM orders WHERE O_ORDERDATE >= %(start)s AND O_ORDERDATE < %(end)s\",\n",
    "    params={\"start\": \"1996-01-01\", \"end\": \"1996-02-01\"},\n",
    "    out_dir=\"parquet_orders_jan\",\n",
    "    base_name=\"orders_jan\",\n",
    "    batch_size=250_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18519e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19217, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36901</td>\n",
       "      <td>O</td>\n",
       "      <td>173665.47</td>\n",
       "      <td>1996-01-02</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000951</td>\n",
       "      <td>0</td>\n",
       "      <td>nstructions sleep furiously among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>39136</td>\n",
       "      <td>O</td>\n",
       "      <td>252004.18</td>\n",
       "      <td>1996-01-10</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000470</td>\n",
       "      <td>0</td>\n",
       "      <td>ly special requests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1284</td>\n",
       "      <td>133972</td>\n",
       "      <td>O</td>\n",
       "      <td>153911.68</td>\n",
       "      <td>1996-01-07</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000492</td>\n",
       "      <td>0</td>\n",
       "      <td>s. blithely silent deposits s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1731</td>\n",
       "      <td>127777</td>\n",
       "      <td>O</td>\n",
       "      <td>317068.68</td>\n",
       "      <td>1996-01-06</td>\n",
       "      <td>1-URGENT</td>\n",
       "      <td>Clerk#000000268</td>\n",
       "      <td>0</td>\n",
       "      <td>lithely regular, final instructions. ironic, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926</td>\n",
       "      <td>92971</td>\n",
       "      <td>O</td>\n",
       "      <td>149651.08</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000568</td>\n",
       "      <td>0</td>\n",
       "      <td>cajole. even warhorses sleep carefully.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0           1      36901             O     173665.47  1996-01-02   \n",
       "1           7      39136             O     252004.18  1996-01-10   \n",
       "2        1284     133972             O     153911.68  1996-01-07   \n",
       "3        1731     127777             O     317068.68  1996-01-06   \n",
       "4        1926      92971             O     149651.08  1996-01-31   \n",
       "\n",
       "  O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0           5-LOW  Clerk#000000951               0   \n",
       "1          2-HIGH  Clerk#000000470               0   \n",
       "2          2-HIGH  Clerk#000000492               0   \n",
       "3        1-URGENT  Clerk#000000268               0   \n",
       "4          2-HIGH  Clerk#000000568               0   \n",
       "\n",
       "                                           O_COMMENT  \n",
       "0                 nstructions sleep furiously among   \n",
       "1                               ly special requests   \n",
       "2                      s. blithely silent deposits s  \n",
       "3  lithely regular, final instructions. ironic, e...  \n",
       "4           cajole. even warhorses sleep carefully.   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Parquet parts back into a single DataFrame\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "\n",
    "def read_parquet_dir(out_dir: str, base_name: str | None = None, columns: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a directory of Parquet part files into a single pandas DataFrame.\n",
    "    - out_dir: directory containing the Parquet parts\n",
    "    - base_name: optional prefix filter like \"orders_jan\" to match files named\n",
    "      \"{base_name}_part_00001.parquet\"; if None, reads all Parquet files in the directory\n",
    "    - columns: optional list of column names to project\n",
    "    \"\"\"\n",
    "    p = Path(out_dir)\n",
    "    if base_name:\n",
    "        files = sorted(p.glob(f\"{base_name}_part_*.parquet\"))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No Parquet parts found matching {base_name}_part_*.parquet in {out_dir}\")\n",
    "        dataset = ds.dataset([str(f) for f in files], format=\"parquet\")\n",
    "    else:\n",
    "        dataset = ds.dataset(str(p), format=\"parquet\")\n",
    "    table = dataset.to_table(columns=columns)\n",
    "    return table.to_pandas()\n",
    "\n",
    "# --- Example: load the data we just wrote ---\n",
    "df_orders_jan = read_parquet_dir(\"parquet_orders_jan\", base_name=\"orders_jan\")\n",
    "print(df_orders_jan.shape)\n",
    "df_orders_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c737526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1112 rows to parquet_orders_schema/orders_part_00001.parquet\n",
      "Wrote 4560 rows to parquet_orders_schema/orders_part_00002.parquet\n",
      "Wrote 6786 rows to parquet_orders_schema/orders_part_00003.parquet\n",
      "Wrote 6786 rows to parquet_orders_schema/orders_part_00003.parquet\n",
      "Wrote 15906 rows to parquet_orders_schema/orders_part_00004.parquet\n",
      "Wrote 15906 rows to parquet_orders_schema/orders_part_00004.parquet\n",
      "Wrote 27055 rows to parquet_orders_schema/orders_part_00005.parquet\n",
      "Wrote 27055 rows to parquet_orders_schema/orders_part_00005.parquet\n",
      "Wrote 57681 rows to parquet_orders_schema/orders_part_00006.parquet\n",
      "Wrote 57681 rows to parquet_orders_schema/orders_part_00006.parquet\n",
      "Wrote 36900 rows to parquet_orders_schema/orders_part_00007.parquet\n",
      "Wrote 1110 rows to parquet_orders_schema/orders_part_00008.parquet\n",
      "Wrote 4539 rows to parquet_orders_schema/orders_part_00009.parquet\n",
      "Wrote 36900 rows to parquet_orders_schema/orders_part_00007.parquet\n",
      "Wrote 1110 rows to parquet_orders_schema/orders_part_00008.parquet\n",
      "Wrote 4539 rows to parquet_orders_schema/orders_part_00009.parquet\n",
      "Wrote 6794 rows to parquet_orders_schema/orders_part_00010.parquet\n",
      "Wrote 6794 rows to parquet_orders_schema/orders_part_00010.parquet\n",
      "Wrote 15898 rows to parquet_orders_schema/orders_part_00011.parquet\n",
      "Wrote 15898 rows to parquet_orders_schema/orders_part_00011.parquet\n",
      "Wrote 27107 rows to parquet_orders_schema/orders_part_00012.parquet\n",
      "Wrote 27107 rows to parquet_orders_schema/orders_part_00012.parquet\n",
      "Wrote 57771 rows to parquet_orders_schema/orders_part_00013.parquet\n",
      "Wrote 57771 rows to parquet_orders_schema/orders_part_00013.parquet\n",
      "Wrote 36781 rows to parquet_orders_schema/orders_part_00014.parquet\n",
      "Wrote 1093 rows to parquet_orders_schema/orders_part_00015.parquet\n",
      "Wrote 4557 rows to parquet_orders_schema/orders_part_00016.parquet\n",
      "Wrote 36781 rows to parquet_orders_schema/orders_part_00014.parquet\n",
      "Wrote 1093 rows to parquet_orders_schema/orders_part_00015.parquet\n",
      "Wrote 4557 rows to parquet_orders_schema/orders_part_00016.parquet\n",
      "Wrote 6785 rows to parquet_orders_schema/orders_part_00017.parquet\n",
      "Wrote 6785 rows to parquet_orders_schema/orders_part_00017.parquet\n",
      "Wrote 15895 rows to parquet_orders_schema/orders_part_00018.parquet\n",
      "Wrote 15895 rows to parquet_orders_schema/orders_part_00018.parquet\n",
      "Wrote 27046 rows to parquet_orders_schema/orders_part_00019.parquet\n",
      "Wrote 27046 rows to parquet_orders_schema/orders_part_00019.parquet\n",
      "Wrote 57656 rows to parquet_orders_schema/orders_part_00020.parquet\n",
      "Wrote 57656 rows to parquet_orders_schema/orders_part_00020.parquet\n",
      "Wrote 36968 rows to parquet_orders_schema/orders_part_00021.parquet\n",
      "Wrote 1105 rows to parquet_orders_schema/orders_part_00022.parquet\n",
      "Wrote 4532 rows to parquet_orders_schema/orders_part_00023.parquet\n",
      "Wrote 36968 rows to parquet_orders_schema/orders_part_00021.parquet\n",
      "Wrote 1105 rows to parquet_orders_schema/orders_part_00022.parquet\n",
      "Wrote 4532 rows to parquet_orders_schema/orders_part_00023.parquet\n",
      "Wrote 6841 rows to parquet_orders_schema/orders_part_00024.parquet\n",
      "Wrote 6841 rows to parquet_orders_schema/orders_part_00024.parquet\n",
      "Wrote 15879 rows to parquet_orders_schema/orders_part_00025.parquet\n",
      "Wrote 15879 rows to parquet_orders_schema/orders_part_00025.parquet\n",
      "Wrote 27089 rows to parquet_orders_schema/orders_part_00026.parquet\n",
      "Wrote 27089 rows to parquet_orders_schema/orders_part_00026.parquet\n",
      "Wrote 57797 rows to parquet_orders_schema/orders_part_00027.parquet\n",
      "Wrote 57797 rows to parquet_orders_schema/orders_part_00027.parquet\n",
      "Wrote 36757 rows to parquet_orders_schema/orders_part_00028.parquet\n",
      "Wrote 1099 rows to parquet_orders_schema/orders_part_00029.parquet\n",
      "Wrote 4554 rows to parquet_orders_schema/orders_part_00030.parquet\n",
      "Wrote 36757 rows to parquet_orders_schema/orders_part_00028.parquet\n",
      "Wrote 1099 rows to parquet_orders_schema/orders_part_00029.parquet\n",
      "Wrote 4554 rows to parquet_orders_schema/orders_part_00030.parquet\n",
      "Wrote 6808 rows to parquet_orders_schema/orders_part_00031.parquet\n",
      "Wrote 6808 rows to parquet_orders_schema/orders_part_00031.parquet\n",
      "Wrote 15929 rows to parquet_orders_schema/orders_part_00032.parquet\n",
      "Wrote 15929 rows to parquet_orders_schema/orders_part_00032.parquet\n",
      "Wrote 26995 rows to parquet_orders_schema/orders_part_00033.parquet\n",
      "Wrote 26995 rows to parquet_orders_schema/orders_part_00033.parquet\n",
      "Wrote 57720 rows to parquet_orders_schema/orders_part_00034.parquet\n",
      "Wrote 57720 rows to parquet_orders_schema/orders_part_00034.parquet\n",
      "Wrote 103846 rows to parquet_orders_schema/orders_part_00035.parquet\n",
      "Wrote 103846 rows to parquet_orders_schema/orders_part_00035.parquet\n",
      "Wrote 83049 rows to parquet_orders_schema/orders_part_00036.parquet\n",
      "Wrote 1094 rows to parquet_orders_schema/orders_part_00037.parquet\n",
      "Wrote 4541 rows to parquet_orders_schema/orders_part_00038.parquet\n",
      "Wrote 6833 rows to parquet_orders_schema/orders_part_00039.parquet\n",
      "Wrote 83049 rows to parquet_orders_schema/orders_part_00036.parquet\n",
      "Wrote 1094 rows to parquet_orders_schema/orders_part_00037.parquet\n",
      "Wrote 4541 rows to parquet_orders_schema/orders_part_00038.parquet\n",
      "Wrote 6833 rows to parquet_orders_schema/orders_part_00039.parquet\n",
      "Wrote 15921 rows to parquet_orders_schema/orders_part_00040.parquet\n",
      "Wrote 15921 rows to parquet_orders_schema/orders_part_00040.parquet\n",
      "Wrote 27068 rows to parquet_orders_schema/orders_part_00041.parquet\n",
      "Wrote 27068 rows to parquet_orders_schema/orders_part_00041.parquet\n",
      "Wrote 57759 rows to parquet_orders_schema/orders_part_00042.parquet\n",
      "Wrote 57759 rows to parquet_orders_schema/orders_part_00042.parquet\n",
      "Wrote 36784 rows to parquet_orders_schema/orders_part_00043.parquet\n",
      "Wrote 1096 rows to parquet_orders_schema/orders_part_00044.parquet\n",
      "Wrote 4533 rows to parquet_orders_schema/orders_part_00045.parquet\n",
      "Wrote 36784 rows to parquet_orders_schema/orders_part_00043.parquet\n",
      "Wrote 1096 rows to parquet_orders_schema/orders_part_00044.parquet\n",
      "Wrote 4533 rows to parquet_orders_schema/orders_part_00045.parquet\n",
      "Wrote 6790 rows to parquet_orders_schema/orders_part_00046.parquet\n",
      "Wrote 6790 rows to parquet_orders_schema/orders_part_00046.parquet\n",
      "Wrote 15912 rows to parquet_orders_schema/orders_part_00047.parquet\n",
      "Wrote 15912 rows to parquet_orders_schema/orders_part_00047.parquet\n",
      "Wrote 27051 rows to parquet_orders_schema/orders_part_00048.parquet\n",
      "Wrote 27051 rows to parquet_orders_schema/orders_part_00048.parquet\n",
      "Wrote 57637 rows to parquet_orders_schema/orders_part_00049.parquet\n",
      "Wrote 57637 rows to parquet_orders_schema/orders_part_00049.parquet\n",
      "Wrote 36981 rows to parquet_orders_schema/orders_part_00050.parquet\n",
      "Wrote 1107 rows to parquet_orders_schema/orders_part_00051.parquet\n",
      "Wrote 4553 rows to parquet_orders_schema/orders_part_00052.parquet\n",
      "Wrote 36981 rows to parquet_orders_schema/orders_part_00050.parquet\n",
      "Wrote 1107 rows to parquet_orders_schema/orders_part_00051.parquet\n",
      "Wrote 4553 rows to parquet_orders_schema/orders_part_00052.parquet\n",
      "Wrote 6795 rows to parquet_orders_schema/orders_part_00053.parquet\n",
      "Wrote 6795 rows to parquet_orders_schema/orders_part_00053.parquet\n",
      "Wrote 15912 rows to parquet_orders_schema/orders_part_00054.parquet\n",
      "Wrote 15912 rows to parquet_orders_schema/orders_part_00054.parquet\n",
      "Wrote 27055 rows to parquet_orders_schema/orders_part_00055.parquet\n",
      "Wrote 27055 rows to parquet_orders_schema/orders_part_00055.parquet\n",
      "Wrote 57672 rows to parquet_orders_schema/orders_part_00056.parquet\n",
      "Wrote 57672 rows to parquet_orders_schema/orders_part_00056.parquet\n",
      "Wrote 103822 rows to parquet_orders_schema/orders_part_00057.parquet\n",
      "Wrote 103822 rows to parquet_orders_schema/orders_part_00057.parquet\n",
      "Wrote 83084 rows to parquet_orders_schema/orders_part_00058.parquet\n",
      "Total rows written to Parquet: 1500000\n",
      "O_ORDERKEY: int64\n",
      "O_CUSTKEY: int64\n",
      "O_ORDERSTATUS: string\n",
      "O_TOTALPRICE: decimal128(12, 2)\n",
      "O_ORDERDATE: date32[day]\n",
      "O_ORDERPRIORITY: string\n",
      "O_CLERK: string\n",
      "O_SHIPPRIORITY: int64\n",
      "O_COMMENT: string\n",
      "Wrote 83084 rows to parquet_orders_schema/orders_part_00058.parquet\n",
      "Total rows written to Parquet: 1500000\n",
      "O_ORDERKEY: int64\n",
      "O_CUSTKEY: int64\n",
      "O_ORDERSTATUS: string\n",
      "O_TOTALPRICE: decimal128(12, 2)\n",
      "O_ORDERDATE: date32[day]\n",
      "O_ORDERPRIORITY: string\n",
      "O_CLERK: string\n",
      "O_SHIPPRIORITY: int64\n",
      "O_COMMENT: string\n"
     ]
    }
   ],
   "source": [
    "# Explicit schema → Parquet type mapping with PyArrow\n",
    "from decimal import Decimal\n",
    "from typing import Optional, Dict, Iterable\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _infer_decimal_precision_scale(values: Iterable[Decimal]) -> tuple[int, int]:\n",
    "    \"\"\"Infer (precision, scale) for a sequence of Decimal values.\"\"\"\n",
    "    max_prec = 1\n",
    "    max_scale = 0\n",
    "    for v in values:\n",
    "        if v is None:\n",
    "            continue\n",
    "        t = v.as_tuple()\n",
    "        digits = len(t.digits)\n",
    "        scale = -t.exponent if t.exponent < 0 else 0\n",
    "        # If number has leading zeros (e.g., 0.01), precision should at least include integer part\n",
    "        int_digits = digits - scale\n",
    "        if int_digits < 1:\n",
    "            int_digits = 1\n",
    "        max_prec = max(max_prec, int_digits + scale)\n",
    "        max_scale = max(max_scale, scale)\n",
    "    # Cap to Arrow/Snowflake common bounds\n",
    "    max_prec = min(max_prec, 38)\n",
    "    max_scale = min(max_scale, 37)\n",
    "    return max_prec, max_scale\n",
    "\n",
    "\n",
    "def pandas_series_to_pa_type(s: pd.Series, decimal_override: Optional[pa.DataType] = None) -> pa.DataType:\n",
    "    \"\"\"Map a pandas Series to an appropriate PyArrow type, with optional decimal override.\"\"\"\n",
    "    if decimal_override is not None:\n",
    "        return decimal_override\n",
    "    dt = s.dtype\n",
    "    if pd.api.types.is_integer_dtype(dt):\n",
    "        # Choose 64-bit to be safe for IDs\n",
    "        return pa.int64()\n",
    "    if pd.api.types.is_bool_dtype(dt):\n",
    "        return pa.bool_()\n",
    "    if pd.api.types.is_float_dtype(dt):\n",
    "        return pa.float64()\n",
    "    if pd.api.types.is_datetime64_any_dtype(dt):\n",
    "        # Use nanosecond precision; add tz if present\n",
    "        tz = getattr(getattr(s, 'dt', None), 'tz', None)\n",
    "        return pa.timestamp('ns', tz=str(tz)) if tz is not None else pa.timestamp('ns')\n",
    "    if pd.api.types.is_object_dtype(dt):\n",
    "        # Try Detect Decimal\n",
    "        non_null = [v for v in s if v is not None]\n",
    "        if non_null and all(isinstance(v, Decimal) for v in non_null):\n",
    "            prec, scale = _infer_decimal_precision_scale(non_null)\n",
    "            return pa.decimal128(precision=prec, scale=scale)\n",
    "        # Fallback to string for mixed/unknown object\n",
    "        return pa.string()\n",
    "    # Default fallback\n",
    "    return pa.string()\n",
    "\n",
    "\n",
    "def build_pa_schema(\n",
    "    df: pd.DataFrame,\n",
    "    decimal_overrides: Optional[Dict[str, pa.DataType]] = None,\n",
    "    explicit_type_overrides: Optional[Dict[str, pa.DataType]] = None,\n",
    "    preserve_order: bool = True,\n",
    " ) -> pa.Schema:\n",
    "    \"\"\"Build a PyArrow schema from a pandas DataFrame.\n",
    "    - decimal_overrides: per-column decimal types (e.g., {'O_TOTALPRICE': pa.decimal128(12,2)})\n",
    "    - explicit_type_overrides: per-column forced types (any pa.DataType)\n",
    "    \"\"\"\n",
    "    fields: list[pa.Field] = []\n",
    "    decimal_overrides = decimal_overrides or {}\n",
    "    explicit_type_overrides = explicit_type_overrides or {}\n",
    "    cols = df.columns if preserve_order else sorted(df.columns)\n",
    "    for col in cols:\n",
    "        if col in explicit_type_overrides:\n",
    "            pa_type = explicit_type_overrides[col]\n",
    "        else:\n",
    "            dec_override = decimal_overrides.get(col)\n",
    "            pa_type = pandas_series_to_pa_type(df[col], dec_override)\n",
    "        fields.append(pa.field(col, pa_type, nullable=True))\n",
    "    return pa.schema(fields)\n",
    "\n",
    "\n",
    "def write_df_parquet_with_schema(\n",
    "    df: pd.DataFrame,\n",
    "    path: str,\n",
    "    schema: Optional[pa.Schema] = None,\n",
    "    compression: str = 'snappy',\n",
    "    coerce_timestamps: Optional[str] = None,\n",
    "    allow_truncated_timestamps: bool = True,\n",
    " ) -> None:\n",
    "    \"\"\"Write a pandas DataFrame to Parquet using a fixed PyArrow schema.\"\"\"\n",
    "    table = pa.Table.from_pandas(\n",
    "        df, schema=schema, preserve_index=False,\n",
    "        safe=True,\n",
    "    )\n",
    "    pq.write_table(\n",
    "        table, path, compression=compression,\n",
    "        coerce_timestamps=coerce_timestamps,\n",
    "        allow_truncated_timestamps=allow_truncated_timestamps,\n",
    "    )\n",
    "\n",
    "\n",
    "def _quant_for_scale(scale: int) -> Decimal:\n",
    "    \"\"\"Return a Decimal quantizer for a given scale (e.g., scale=2 -> Decimal('0.01')).\"\"\"\n",
    "    if scale <= 0:\n",
    "        return Decimal('1')\n",
    "    return Decimal('0.' + ('0' * (scale - 1)) + '1')\n",
    "\n",
    "\n",
    "def coerce_df_to_schema(df: pd.DataFrame, schema: pa.Schema) -> pd.DataFrame:\n",
    "    \"\"\"Coerce pandas DataFrame columns to types compatible with the provided Arrow schema.\n",
    "\n",
    "    - Decimal fields: convert values to Decimal with the correct scale.\n",
    "    - Date32 fields: convert to Python date objects.\n",
    "    - Int64 fields: cast to pandas nullable Int64 where possible.\n",
    "    - String fields: cast to pandas string dtype.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    for field in schema:\n",
    "        name = field.name\n",
    "        if name not in out.columns:\n",
    "            continue\n",
    "        at = field.type\n",
    "        s = out[name]\n",
    "        try:\n",
    "            if pa.types.is_decimal(at):\n",
    "                scale = at.scale\n",
    "                q = _quant_for_scale(scale)\n",
    "                out[name] = s.apply(lambda x: None if pd.isna(x) else (x if isinstance(x, Decimal) else Decimal(str(x))).quantize(q))\n",
    "            elif pa.types.is_date32(at) or pa.types.is_date64(at):\n",
    "                out[name] = pd.to_datetime(s, errors='coerce').dt.date\n",
    "            elif pa.types.is_integer(at):\n",
    "                # Best effort to coerce numerics to Int64 (nullable)\n",
    "                out[name] = pd.to_numeric(s, errors='coerce').astype('Int64')\n",
    "            elif pa.types.is_string(at):\n",
    "                out[name] = s.astype('string')\n",
    "            # Other types fall back to original\n",
    "        except Exception:\n",
    "            # If coercion fails, leave the column as-is; Arrow may still handle it\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "\n",
    "def stream_to_parquet_dir_with_schema(\n",
    "    sql: str,\n",
    "    params: Optional[Dict] = None,\n",
    "    out_dir: str = 'parquet_out',\n",
    "    base_name: str = 'result',\n",
    "    batch_size: int = 200_000,\n",
    "    decimal_overrides: Optional[Dict[str, pa.DataType]] = None,\n",
    "    explicit_type_overrides: Optional[Dict[str, pa.DataType]] = None,\n",
    "    compression: str = 'snappy',\n",
    " ) -> tuple[int, pa.Schema]:\n",
    "    \"\"\"Stream query results and write Parquet files using a consistent, explicit schema.\n",
    "    Returns (total_rows_written, schema_used).\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    total = 0\n",
    "    schema_used: Optional[pa.Schema] = None\n",
    "    for i, df_part in enumerate(fetch_df_batches(sql, params=params, batch_size=batch_size), start=1):\n",
    "        if schema_used is None:\n",
    "            schema_used = build_pa_schema(\n",
    "                df_part,\n",
    "                decimal_overrides=decimal_overrides,\n",
    "                explicit_type_overrides=explicit_type_overrides,\n",
    "            )\n",
    "        # Coerce pandas dtypes to match target Arrow schema (Decimal/Date/etc.)\n",
    "        df_coerced = coerce_df_to_schema(df_part, schema_used)\n",
    "        part_path = Path(out_dir) / f\"{base_name}_part_{i:05d}.parquet\"\n",
    "        write_df_parquet_with_schema(\n",
    "            df_coerced, str(part_path), schema=schema_used, compression=compression\n",
    "        )\n",
    "        total += len(df_part)\n",
    "        print(f\"Wrote {len(df_part)} rows to {part_path}\")\n",
    "    if schema_used is None:\n",
    "        # No rows; build empty schema using overrides if provided\n",
    "        empty_df = pd.DataFrame({})\n",
    "        schema_used = build_pa_schema(empty_df)\n",
    "    print(f\"Total rows written to Parquet: {total}\")\n",
    "    return total, schema_used\n",
    "\n",
    "\n",
    "# --- Example (uncomment to run with your environment) ---\n",
    "decimal_map = {\n",
    "    \"O_TOTALPRICE\": pa.decimal128(12, 2),\n",
    "}\n",
    "explicit_map = {\n",
    "    \"O_ORDERKEY\": pa.int64(),       # NUMBER(38,0)\n",
    "    \"O_CUSTKEY\": pa.int64(),        # NUMBER(38,0)\n",
    "    \"O_SHIPPRIORITY\": pa.int64(),   # NUMBER(38,0)\n",
    "    \"O_ORDERDATE\": pa.date32(),     # DATE → date32\n",
    "    # VARCHAR columns default to string\n",
    "}\n",
    "total, schema_used = stream_to_parquet_dir_with_schema(\n",
    "    \"SELECT O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, O_TOTALPRICE, O_ORDERDATE, O_ORDERPRIORITY, O_CLERK, O_SHIPPRIORITY, O_COMMENT FROM orders WHERE O_TOTALPRICE > %(min_total)s\",\n",
    "    params={\"min_total\": 100},\n",
    "    out_dir=\"parquet_orders_schema\",\n",
    "    base_name=\"orders\",\n",
    "    batch_size=250_000,\n",
    "    decimal_overrides=decimal_map,\n",
    "    explicit_type_overrides=explicit_map,\n",
    ")\n",
    "print(schema_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19217, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36901</td>\n",
       "      <td>O</td>\n",
       "      <td>173665.47</td>\n",
       "      <td>1996-01-02</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000951</td>\n",
       "      <td>0</td>\n",
       "      <td>nstructions sleep furiously among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>39136</td>\n",
       "      <td>O</td>\n",
       "      <td>252004.18</td>\n",
       "      <td>1996-01-10</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000470</td>\n",
       "      <td>0</td>\n",
       "      <td>ly special requests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1284</td>\n",
       "      <td>133972</td>\n",
       "      <td>O</td>\n",
       "      <td>153911.68</td>\n",
       "      <td>1996-01-07</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000492</td>\n",
       "      <td>0</td>\n",
       "      <td>s. blithely silent deposits s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1731</td>\n",
       "      <td>127777</td>\n",
       "      <td>O</td>\n",
       "      <td>317068.68</td>\n",
       "      <td>1996-01-06</td>\n",
       "      <td>1-URGENT</td>\n",
       "      <td>Clerk#000000268</td>\n",
       "      <td>0</td>\n",
       "      <td>lithely regular, final instructions. ironic, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926</td>\n",
       "      <td>92971</td>\n",
       "      <td>O</td>\n",
       "      <td>149651.08</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000568</td>\n",
       "      <td>0</td>\n",
       "      <td>cajole. even warhorses sleep carefully.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0           1      36901             O     173665.47  1996-01-02   \n",
       "1           7      39136             O     252004.18  1996-01-10   \n",
       "2        1284     133972             O     153911.68  1996-01-07   \n",
       "3        1731     127777             O     317068.68  1996-01-06   \n",
       "4        1926      92971             O     149651.08  1996-01-31   \n",
       "\n",
       "  O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0           5-LOW  Clerk#000000951               0   \n",
       "1          2-HIGH  Clerk#000000470               0   \n",
       "2          2-HIGH  Clerk#000000492               0   \n",
       "3        1-URGENT  Clerk#000000268               0   \n",
       "4          2-HIGH  Clerk#000000568               0   \n",
       "\n",
       "                                           O_COMMENT  \n",
       "0                 nstructions sleep furiously among   \n",
       "1                               ly special requests   \n",
       "2                      s. blithely silent deposits s  \n",
       "3  lithely regular, final instructions. ironic, e...  \n",
       "4           cajole. even warhorses sleep carefully.   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
